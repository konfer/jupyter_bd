{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.avg\n",
    "import org.apache.spark.sql.SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:29: error: not found: value data_df\n       data_df = sc.create\n       ^\n<console>:30: error: not found: value data_df\n       val $ires3 = data_df\n                    ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "data_df = sc.create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.SparkContext@9c12cec"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@73c34c5f"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:30: error: value buider is not a member of org.apache.spark.sql.SparkSession\n       spark.buider.appName(\"AuthorsAges\").getOrCreate()\n             ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "spark.buider.appName(\"AuthorsAges\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:29: error: value buider is not a member of org.apache.spark.sql.SparkSession\n       val spark_ = spark.buider.appName(\"AuthorsAges\").getOrCreate()\n                          ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "val spark_ = spark.buider.appName(\"AuthorsAges\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:1: error: illegal start of simple expression\n       val data_df = spark_.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),(\"TD\", 35), (\"Brooke\", 25)],\n                                            ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "val data_df = spark_.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),(\"TD\", 35), (\"Brooke\", 25)], \n",
    "                                 [\"name\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:28: error: not found: value data_df\n       data_df.printSchema\n       ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "data_df.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:27: error: not found: value avg_df\n       avg_df = data_df.groupby(\"name\").agg(avg(\"age\"))\n       ^\n<console>:28: error: not found: value avg_df\n       val $ires10 = avg_df\n                     ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "avg_df = data_df.groupby(\"name\").agg(avg(\"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:28: error: ambiguous reference to overloaded definition,\nboth method avg in object functions of type (columnName: String)org.apache.spark.sql.Column\nand  method avg in object functions of type (e: org.apache.spark.sql.Column)org.apache.spark.sql.Column\nmatch expected type ?\n       avg.df.show()\n       ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "avg.df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:1: error: illegal start of simple expression\n       dataRDD = sc.parallelize([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n                                ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "dataRDD = sc.parallelize([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    "(\"TD\", 35), (\"Brooke\", 25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:2: error: identifier expected but integer literal found.\n       .map(lambda x: (x[0], (x[1], 1)))\n                         ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "agesRDD = (dataRDD\n",
    ".map(lambda x: (x[0], (x[1], 1)))\n",
    ".reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1])) .map(lambda x: (x[0], x[1][0]/x[1][1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:28: error: not found: value dataRDD\n       dataRDD\n       ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "dataRDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i = 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val i = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:30: error: reassignment to val\n       i=\"str\"\n        ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "i=\"str\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:30: error: missing parameter type for expanded function ((x$1: <error>) => x$1.$plus(_jk))\n       sc.parallelize(1 to 100).reduce(_+_jk)\n                                       ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "sc.parallelize(1 to 100).reduce(_+_jk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spark = org.apache.spark.sql.SparkSession@73c34c5f\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "org.apache.spark.sql.SparkSession@73c34c5f"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = SparkSession.builder.appName(\"AuthorsAges\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:1: error: illegal start of simple expression\n       val data_df = spark_.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),(\"TD\", 35), (\"Brooke\", 25)],\n                                            ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "val data_df = spark_.createDataFrame([(\"Brooke\", 20), (\"Denny\", 31), (\"Jules\", 30),\n",
    "                                      (\"TD\", 35), (\"Brooke\", 25)], \n",
    "                                 [\"name\", \"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:28: error: not found: value data_df\n       data_df\n       ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dataDF = [name: string, age: int]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[name: string, age: int]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val dataDF = spark.createDataFrame(Seq((\"Brooke\", 20), (\"Brooke\", 25), (\"Denny\", 31), (\"Jules\", 30), (\"TD\", 35))).toDF(\"name\", \"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avgDF = [name: string, avg(age): double]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[name: string, avg(age): double]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val avgDF = dataDF.groupBy(\"name\").agg(avg(\"age\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  name|avg(age)|\n",
      "+------+--------+\n",
      "|Brooke|    22.5|\n",
      "| Jules|    30.0|\n",
      "|    TD|    35.0|\n",
      "| Denny|    31.0|\n",
      "+------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "avgDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: string, age: int]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "Compile Error",
     "evalue": "<console>:30: error: missing argument list for method describe in class Dataset\nUnapplied methods are only converted to functions when a function type is expected.\nYou can make this conversion explicit by writing `describe _` or `describe(_)` instead of `describe`.\n       dataDF.describe\n              ^\n",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "dataDF.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: string, age: int]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataDF.toString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+\n",
      "|  name|age|\n",
      "+------+---+\n",
      "|Brooke| 20|\n",
      "|Brooke| 25|\n",
      "| Denny| 31|\n",
      "| Jules| 30|\n",
      "|    TD| 35|\n",
      "+------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataDF.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Apache Toree - Scala",
   "language": "scala",
   "name": "apache_toree_scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "pygments_lexer": "scala",
   "version": "2.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
