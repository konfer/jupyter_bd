{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "什么是embedding?\n",
    "\n",
    "1. 从数学上看, 是映射\n",
    "2. 从神经⽹络的⾓度看, 是层与层之间的矩阵\n",
    "3. 从特征的⾓度看, 是从⼀套特征映射到另⼀种表⽰⽅式\n",
    "\n",
    "本节课, 我们从非监督学习和监督学习两个角度, 来讨论embedding的使用."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/usr/local/codeData/RS-J2/3--data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column for Make Model\n",
    "df['Maker_Model']= df['Make']+ \" \" + df['Model']\n",
    "\n",
    "# Select features from original dataset to form a new dataframe \n",
    "df1 = df[['Engine Fuel Type','Transmission Type','Driven_Wheels','Market Category','Vehicle Size', 'Vehicle Style', 'Maker_Model']]\n",
    "# For each row, combine all the columns into one column\n",
    "df2 = df1.apply(lambda x: ','.join(x.astype(str)), axis=1)\n",
    "# Store them in a pandas dataframe\n",
    "df_clean = pd.DataFrame({'clean': df2})\n",
    "# Create the list of list format of the custom corpus for gensim modeling \n",
    "sent = [row.split(',') for row in df_clean['clean']]\n",
    "# show the example of list of list format of the custom corpus for gensim modeling \n",
    "sent[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "#model = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 1)\n",
    "#__init__() got an unexpected keyword argument 'size'\n",
    "model = Word2Vec(sent, min_count=1,workers=3, window =3, sg = 1,vector_size = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['MANUAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('Porsche 718 Cayman', 'Nissan Van')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.similarity('Porsche 718 Cayman', 'Mercedes-Benz SLK-Class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv.most_similar('Mercedes-Benz SLK-Class')[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_closestwords_tsnescatterplot(model, word, size):\n",
    "    arr = np.empty((0,size), dtype='f')\n",
    "    word_labels = [word]\n",
    "    close_words = model.wv.similar_by_word(word)\n",
    "    arr = np.append(arr, np.array([model.wv[word]]), axis=0)\n",
    "\n",
    "    for wrd_score in close_words:\n",
    "        wrd_vector = model.wv[wrd_score[0]]\n",
    "        word_labels.append(wrd_score[0])\n",
    "        arr = np.append(arr, np.array([wrd_vector]), axis=0)\n",
    "        \n",
    "    tsne = TSNE(n_components=2, random_state=0)\n",
    "    np.set_printoptions(suppress=True)\n",
    "    Y = tsne.fit_transform(arr)\n",
    "    x_coords = Y[:, 0]\n",
    "    y_coords = Y[:, 1]\n",
    "    plt.scatter(x_coords, y_coords)\n",
    "\n",
    "    for label, x, y in zip(word_labels, x_coords, y_coords):\n",
    "        plt.annotate(label, xy=(x, y), xytext=(0, 0), textcoords='offset points')\n",
    "        plt.xlim(x_coords.min()+0.00005, x_coords.max()+0.00005)\n",
    "        plt.ylim(y_coords.min()+0.00005, y_coords.max()+0.00005)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_closestwords_tsnescatterplot(model, 'Porsche 718 Cayman',50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train([[\"hello\", \"world\"]], total_examples=1, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array = np.random.randint(1000, size=(32, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.model import Sequential\n",
    "# from tf.keras.layers import Embedding\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Embedding(1000, 64, input_length=10))\n",
    "# the model will take as input an integer matrix of size (batch,\n",
    "# input_length).\n",
    "# the largest integer (i.e. word index) in the input should be no larger\n",
    "# than 999 (vocabulary size).\n",
    "# now model.output_shape == (None, 10, 64), where None is the batch\n",
    "# dimension.\n",
    "\n",
    "input_array = np.random.randint(1000, size=(32, 10))\n",
    "\n",
    "model.compile('rmsprop', 'mse')\n",
    "output_array = model.predict(input_array)\n",
    "assert output_array.shape == (32, 10, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Lookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.compat.v1.Session() as sess:\n",
    "    c = np.random.random([10, 1])\n",
    "    b = tf.nn.embedding_lookup(c, [0,1,2,3])\n",
    "    print(c)\n",
    "    print(sess.run(b))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
